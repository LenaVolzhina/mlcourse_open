{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Habr](https://habrahabr.ru/company/ods/blog/327242/)\n",
    "# Временные ряды\n",
    "\n",
    "## Движемся, сглаживаем, оцениваем\n",
    "#### Rolling window\n",
    "* скользящее среднее [DataFrame.rolling(window).mean()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rolling.html)\n",
    "* оно же, но с весами (обычно более близким событиям -- больше)\n",
    "\n",
    "#### Экспоненциальное сглаживание, модель Хольта-Винтерса\n",
    "* простое эксп. сглаживание: используем все прошлое, но с уменьшающимися экспоненциально весами $\\hat{y}_{t} = \\alpha \\cdot y_t + (1-\\alpha) \\cdot \\hat y_{t-1}$, где $\\alpha$ -- сглаживающий фактор (чем больше, тем больше используется прошлое)\n",
    "* двойное эксп. сглаживание: пытаемся предсказывать отдельно уровень (level, intercept) и тренд (trend, slope). Подбирать уже два параметры сглаживания\n",
    "* тройное эксп. сглаживание: добавляем сезонность (с фиксированной длиной сезона)\n",
    "\n",
    "Итого перешли от предсказывания 1 значения через 2 к бесконечному числу\n",
    "\n",
    "#### Кросс-валидация на временных рядах, подбор параметров\n",
    "Оценка ошибки как обычно -- выбираем функцию потерь, считаем градиент, двигаемся к лучшим параметрам.\n",
    "\n",
    "Проблема в кросс-валидации: данные нельзя просто перемешать. Рабочий вариант -- \"cross-validation on a rolling basis\" (кросс-валидация на скользящем окне). Идея -- обучаемся на кусочке, предсказываем следующие n, считаемся. Добавляем эти n к обучению, повторяем\n",
    "\n",
    "## Эконометрический подход\n",
    "#### Стационарность, единичные корни\n",
    "Стационарность: статистические характеристики не меняются\n",
    "* постоянство матожидания\n",
    "* постоянство дисперсии (гомоскедастичность)\n",
    "* независимость ковариационной функции от времени (только от расстояния между значениями)\n",
    "К сожалению, это редко бывает в реальном мире, но к этому можно стремиться\n",
    "\n",
    "Проверка стационарности: `sm.tsa.stattools.adfuller(x)[1]`, [тест Дики Фуллера](https://ru.wikipedia.org/wiki/Тест_Дики_—_Фуллера). H0 -- ряд стационарен\n",
    "\n",
    "#### Борьба с нестационарностью\n",
    "Бороться с нестационарностью можно множеством способов — разностями различного порядка, выделением тренда и сезонности, сглаживаниями и преобразованиями, например, Бокса-Кокса или логарифмированием.\n",
    "\n",
    "[Пример про Бокса-Кокса]\n",
    "\n",
    "Чо-та лень\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейные и не очень модели на временных рядах\n",
    "Давайте просто фич повыделяем и обучим что-нибудь.\n",
    "\n",
    "#### Feature extraction\n",
    "[Дата-время](https://habrahabr.ru/company/ods/blog/325422/#data-i-vremya)\n",
    "* one-hot encoding дней недели, месяцев etc. Выходные.\n",
    "* время -- сложно. Плохой полный порядок, но не хотим терять инфу о близости -- можно на окружность переложить\n",
    "\n",
    "Еще хорошо работает средний для категории (по трейну!). Также максимальное/минимальное значение, наблюдавшееся в скользящем по ряду окне, медианы, число пиков, взвешенные дисперсии и многое другое. Автоматически этим занимается уже упоминавшаяся в курсе библиотека [библиотека tsfresh](https://github.com/blue-yonder/tsfresh)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Линейная регрессия\n",
    "\n",
    "Обучим на получившихся данных простую линейную регрессию. При этом **лаги будем брать начиная с двенадцатого**, таким образом модель будет способна строить предсказания на 12 часов вперёд, имея фактические наблюдения за предыдущие пол дня."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepareData(data, lag_start=5, lag_end=20, test_size=0.15):\n",
    "\n",
    "    data = pd.DataFrame(data.copy())\n",
    "    data.columns = [\"y\"]\n",
    "\n",
    "    # считаем индекс в датафрейме, после которого начинается тестовыый отрезок\n",
    "    test_index = int(len(data)*(1-test_size))\n",
    "\n",
    "    # добавляем лаги исходного ряда в качестве признаков\n",
    "    for i in range(lag_start, lag_end):\n",
    "        data[\"lag_{}\".format(i)] = data.y.shift(i)\n",
    "\n",
    "    data.index = data.index.to_datetime()\n",
    "    data[\"hour\"] = data.index.hour\n",
    "    data[\"weekday\"] = data.index.weekday\n",
    "    data['is_weekend'] = data.weekday.isin([5,6])*1\n",
    "\n",
    "    # считаем средние только по тренировочной части, чтобы избежать лика\n",
    "    data['weekday_average'] = map(code_mean(data[:test_index], 'weekday', \"y\").get, data.weekday)\n",
    "    data[\"hour_average\"] = map(code_mean(data[:test_index], 'hour', \"y\").get, data.hour)\n",
    "\n",
    "    # выкидываем закодированные средними признаки \n",
    "    data.drop([\"hour\", \"weekday\"], axis=1, inplace=True)\n",
    "\n",
    "    data = data.dropna()\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    # разбиваем весь датасет на тренировочную и тестовую выборку\n",
    "    X_train = data.loc[:test_index].drop([\"y\"], axis=1)\n",
    "    y_train = data.loc[:test_index][\"y\"]\n",
    "    X_test = data.loc[test_index:].drop([\"y\"], axis=1)\n",
    "    y_test = data.loc[test_index:][\"y\"]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = prepareData(dataset.Users, test_size=0.3, lag_start=12, lag_end=48)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "prediction = lr.predict(X_test)\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(prediction, \"r\", label=\"prediction\")\n",
    "plt.plot(y_test.values, label=\"actual\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Linear regression\\n Mean absolute error {} users\".format(round(mean_absolute_error(prediction, y_test))))\n",
    "plt.grid(True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Кросс-валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performTimeSeriesCV(X_train, y_train, number_folds, model, metrics):\n",
    "    print('Size train set: {}'.format(X_train.shape))\n",
    "\n",
    "    k = int(np.floor(float(X_train.shape[0]) / number_folds))\n",
    "    print('Size of each fold: {}'.format(k))\n",
    "\n",
    "    errors = np.zeros(number_folds-1)\n",
    "\n",
    "    # loop from the first 2 folds to the total number of folds    \n",
    "    for i in range(2, number_folds + 1):\n",
    "        print('')\n",
    "        split = float(i-1)/i\n",
    "        print('Splitting the first ' + str(i) + ' chunks at ' + str(i-1) + '/' + str(i) )\n",
    "\n",
    "        X = X_train[:(k*i)]\n",
    "        y = y_train[:(k*i)]\n",
    "        print('Size of train + test: {}'.format(X.shape)) # the size of the dataframe is going to be k*i\n",
    "\n",
    "        index = int(np.floor(X.shape[0] * split))\n",
    "\n",
    "        # folds used to train the model        \n",
    "        X_trainFolds = X[:index]        \n",
    "        y_trainFolds = y[:index]\n",
    "\n",
    "        # fold used to test the model\n",
    "        X_testFold = X[(index + 1):]\n",
    "        y_testFold = y[(index + 1):]\n",
    "\n",
    "        model.fit(X_trainFolds, y_trainFolds)\n",
    "        errors[i-2] = metrics(model.predict(X_testFold), y_testFold)\n",
    "\n",
    "    # the function returns the mean of the errors on the n-1 folds    \n",
    "    return errors.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
