{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучаем однопроходные модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_1_ngram_1_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = hw8_data/stackoverflow_train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      161\n",
      "0.500000 1.000000            2            2.0        4        1       68\n",
      "0.750000 1.000000            4            4.0        7        1       88\n",
      "0.750000 0.750000            8            8.0        7        1       95\n",
      "0.750000 0.750000           16           16.0        7        7      209\n",
      "0.781250 0.812500           32           32.0        7        2      174\n",
      "0.765625 0.750000           64           64.0        3        3      204\n",
      "0.648438 0.531250          128          128.0        1        5       29\n",
      "0.609375 0.570312          256          256.0        5        1      169\n",
      "0.548828 0.488281          512          512.0        2        2      303\n",
      "0.456055 0.363281         1024         1024.0        3        3      123\n",
      "0.375000 0.293945         2048         2048.0        1        5       83\n",
      "0.309082 0.243164         4096         4096.0        1        1       79\n",
      "0.261841 0.214600         8192         8192.0        2        2      112\n",
      "0.220825 0.179810        16384        16384.0        7        7      252\n",
      "0.186096 0.151367        32768        32768.0        4        5      134\n",
      "0.159149 0.132202        65536        65536.0        5        5      145\n",
      "0.138329 0.117508       131072       131072.0        7        2      255\n",
      "0.120888 0.103447       262144       262144.0        7        7      101\n",
      "0.108549 0.096210       524288       524288.0        1        1      818\n",
      "0.099817 0.091085      1048576      1048576.0        1        1      571\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.095764\n",
      "total feature number = 291954690\n",
      "Generating 2-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_1_ngram_2_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = hw8_data/stackoverflow_train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      320\n",
      "0.500000 1.000000            2            2.0        4        1      134\n",
      "0.750000 1.000000            4            4.0        7        1      174\n",
      "0.750000 0.750000            8            8.0        7        1      188\n",
      "0.750000 0.750000           16           16.0        7        7      416\n",
      "0.781250 0.812500           32           32.0        7        2      346\n",
      "0.750000 0.718750           64           64.0        3        3      406\n",
      "0.648438 0.546875          128          128.0        1        7       56\n",
      "0.617188 0.585938          256          256.0        5        1      336\n",
      "0.548828 0.480469          512          512.0        2        2      604\n",
      "0.454102 0.359375         1024         1024.0        3        3      244\n",
      "0.375000 0.295898         2048         2048.0        1        5      164\n",
      "0.306396 0.237793         4096         4096.0        1        1      156\n",
      "0.254761 0.203125         8192         8192.0        2        2      222\n",
      "0.211426 0.168091        16384        16384.0        7        7      502\n",
      "0.176117 0.140808        32768        32768.0        4        5      266\n",
      "0.147873 0.119629        65536        65536.0        5        5      288\n",
      "0.126411 0.104950       131072       131072.0        7        2      508\n",
      "0.108402 0.090393       262144       262144.0        7        7      200\n",
      "0.097092 0.085781       524288       524288.0        1        1     1634\n",
      "0.086005 0.074919      1048576      1048576.0        1        1     1140\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.081809\n",
      "total feature number = 580983344\n",
      "Generating 3-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_1_ngram_3_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = hw8_data/stackoverflow_train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      478\n",
      "0.500000 1.000000            2            2.0        4        1      199\n",
      "0.750000 1.000000            4            4.0        7        1      259\n",
      "0.750000 0.750000            8            8.0        7        1      280\n",
      "0.750000 0.750000           16           16.0        7        7      622\n",
      "0.781250 0.812500           32           32.0        7        2      517\n",
      "0.750000 0.718750           64           64.0        3        3      607\n",
      "0.648438 0.546875          128          128.0        1        7       82\n",
      "0.628906 0.609375          256          256.0        5        1      502\n",
      "0.564453 0.500000          512          512.0        2        2      904\n",
      "0.471680 0.378906         1024         1024.0        3        3      364\n",
      "0.400879 0.330078         2048         2048.0        1        5      244\n",
      "0.333252 0.265625         4096         4096.0        1        1      232\n",
      "0.281006 0.228760         8192         8192.0        2        2      331\n",
      "0.232361 0.183716        16384        16384.0        7        7      751\n",
      "0.192169 0.151978        32768        32768.0        4        5      397\n",
      "0.160690 0.129211        65536        65536.0        5        5      430\n",
      "0.136086 0.111481       131072       131072.0        7        2      760\n",
      "0.115993 0.095901       262144       262144.0        7        7      298\n",
      "0.102705 0.089417       524288       524288.0        1        1     2449\n",
      "0.090337 0.077969      1048576      1048576.0        1        1     1708\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.085885\n",
      "total feature number = 868548985\n",
      "Generating 1-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_3_ngram_1_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using no cache\n",
      "Reading datafile = hw8_data/stackoverflow_train.vw\n",
      "Error: need a cache file for multiple passes : try using --cache_file\n",
      "\n",
      "finished run\n",
      "number of examples = 0\n",
      "weighted example sum = 0.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = undefined (no holdout)\n",
      "total feature number = 0\n",
      "vw (parser.cc:668): need a cache file for multiple passes : try using --cache_file\n",
      "Generating 2-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_3_ngram_2_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using no cache\n",
      "Reading datafile = hw8_data/stackoverflow_train.vw\n",
      "Error: need a cache file for multiple passes : try using --cache_file\n",
      "\n",
      "finished run\n",
      "number of examples = 0\n",
      "weighted example sum = 0.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = undefined (no holdout)\n",
      "total feature number = 0\n",
      "vw (parser.cc:668): need a cache file for multiple passes : try using --cache_file\n",
      "Generating 3-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_3_ngram_3_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using no cache\n",
      "Reading datafile = hw8_data/stackoverflow_train.vw\n",
      "Error: need a cache file for multiple passes : try using --cache_file\n",
      "\n",
      "finished run\n",
      "number of examples = 0\n",
      "weighted example sum = 0.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = undefined (no holdout)\n",
      "total feature number = 0\n",
      "vw (parser.cc:668): need a cache file for multiple passes : try using --cache_file\n",
      "Generating 1-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_5_ngram_1_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using no cache\n",
      "Reading datafile = hw8_data/stackoverflow_train.vw\n",
      "Error: need a cache file for multiple passes : try using --cache_file\n",
      "\n",
      "finished run\n",
      "number of examples = 0\n",
      "weighted example sum = 0.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = undefined (no holdout)\n",
      "total feature number = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vw (parser.cc:668): need a cache file for multiple passes : try using --cache_file\n",
      "Generating 2-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_5_ngram_2_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using no cache\n",
      "Reading datafile = hw8_data/stackoverflow_train.vw\n",
      "Error: need a cache file for multiple passes : try using --cache_file\n",
      "\n",
      "finished run\n",
      "number of examples = 0\n",
      "weighted example sum = 0.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = undefined (no holdout)\n",
      "total feature number = 0\n",
      "vw (parser.cc:668): need a cache file for multiple passes : try using --cache_file\n",
      "Generating 3-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_5_ngram_3_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using no cache\n",
      "Reading datafile = hw8_data/stackoverflow_train.vw\n",
      "Error: need a cache file for multiple passes : try using --cache_file\n",
      "\n",
      "finished run\n",
      "number of examples = 0\n",
      "weighted example sum = 0.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = undefined (no holdout)\n",
      "total feature number = 0\n",
      "vw (parser.cc:668): need a cache file for multiple passes : try using --cache_file\n"
     ]
    }
   ],
   "source": [
    "!vw --oaa 10 -d hw8_data/stackoverflow_train.vw -f hw8_data/models/passes_1_ngram_1_model.vw  \\\n",
    "    --loss_function hinge --bit_precision 28 --random_seed 17  \\\n",
    "    --passes 1 --ngram 1\n",
    "\n",
    "!vw --oaa 10 -d hw8_data/stackoverflow_train.vw -f hw8_data/models/passes_1_ngram_2_model.vw  \\\n",
    "    --loss_function hinge --bit_precision 28 --random_seed 17  \\\n",
    "    --passes 1 --ngram 2\n",
    "\n",
    "!vw --oaa 10 -d hw8_data/stackoverflow_train.vw -f hw8_data/models/passes_1_ngram_3_model.vw  \\\n",
    "    --loss_function hinge --bit_precision 28 --random_seed 17  \\\n",
    "    --passes 1 --ngram 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучаем 3- и 5-проходные модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_3_ngram_1_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = cache.vw\n",
      "Reading datafile = hw8_data/stackoverflow_train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      161\n",
      "0.500000 1.000000            2            2.0        4        1       68\n",
      "0.750000 1.000000            4            4.0        7        1       88\n",
      "0.750000 0.750000            8            8.0        7        1       95\n",
      "0.750000 0.750000           16           16.0        2        7      159\n",
      "0.750000 0.750000           32           32.0        1        7      404\n",
      "0.703125 0.656250           64           64.0        7        7      103\n",
      "0.617188 0.531250          128          128.0        5        5      276\n",
      "0.593750 0.570312          256          256.0        1        1      102\n",
      "0.533203 0.472656          512          512.0        2        5       68\n",
      "0.457031 0.380859         1024         1024.0        1        1      132\n",
      "0.383301 0.309570         2048         2048.0        7        7       71\n",
      "0.310059 0.236816         4096         4096.0        2        2      319\n",
      "0.262085 0.214111         8192         8192.0        5        5       24\n",
      "0.223450 0.184814        16384        16384.0        3        3      581\n",
      "0.185547 0.147644        32768        32768.0        3        3       28\n",
      "0.158493 0.131439        65536        65536.0        4        4      184\n",
      "0.137115 0.115738       131072       131072.0        2        2       95\n",
      "0.121109 0.105103       262144       262144.0        5        5      232\n",
      "0.108404 0.095699       524288       524288.0        6        6      142\n",
      "0.100007 0.091610      1048576      1048576.0        1        1      422\n",
      "0.092582 0.092582      2097152      2097152.0        5        5      696 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1316717\n",
      "passes used = 3\n",
      "weighted example sum = 3950151.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.084107 h\n",
      "total feature number = 788274150\n",
      "Generating 2-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_3_ngram_2_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = cache.vw\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      320\n",
      "0.500000 1.000000            2            2.0        4        1      134\n",
      "0.750000 1.000000            4            4.0        7        1      174\n",
      "0.750000 0.750000            8            8.0        7        1      188\n",
      "0.750000 0.750000           16           16.0        2        7      316\n",
      "0.718750 0.687500           32           32.0        1        7      806\n",
      "0.703125 0.687500           64           64.0        7        7      204\n",
      "0.632812 0.562500          128          128.0        5        5      550\n",
      "0.609375 0.585938          256          256.0        1        1      202\n",
      "0.531250 0.453125          512          512.0        2        5      134\n",
      "0.458984 0.386719         1024         1024.0        1        1      262\n",
      "0.382812 0.306641         2048         2048.0        7        7      140\n",
      "0.305664 0.228516         4096         4096.0        2        2      636\n",
      "0.255249 0.204834         8192         8192.0        5        7       46\n",
      "0.215027 0.174805        16384        16384.0        3        3     1160\n",
      "0.177612 0.140198        32768        32768.0        3        3       54\n",
      "0.148590 0.119568        65536        65536.0        4        4      366\n",
      "0.127281 0.105972       131072       131072.0        2        2      188\n",
      "0.110416 0.093552       262144       262144.0        5        5      462\n",
      "0.096605 0.082794       524288       524288.0        6        6      282\n",
      "0.086320 0.076035      1048576      1048576.0        1        1      842\n",
      "0.077806 0.077806      2097152      2097152.0        5        5     1390 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1316717\n",
      "passes used = 3\n",
      "weighted example sum = 3950151.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.069835 h\n",
      "total feature number = 1568647998\n",
      "Generating 3-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_3_ngram_3_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = cache.vw\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      478\n",
      "0.500000 1.000000            2            2.0        4        1      199\n",
      "0.750000 1.000000            4            4.0        7        1      259\n",
      "0.750000 0.750000            8            8.0        7        1      280\n",
      "0.750000 0.750000           16           16.0        2        7      472\n",
      "0.718750 0.687500           32           32.0        1        7     1207\n",
      "0.687500 0.656250           64           64.0        7        7      304\n",
      "0.640625 0.593750          128          128.0        5        1      823\n",
      "0.625000 0.609375          256          256.0        1        1      301\n",
      "0.544922 0.464844          512          512.0        2        1      199\n",
      "0.466797 0.388672         1024         1024.0        1        1      391\n",
      "0.402344 0.337891         2048         2048.0        7        7      208\n",
      "0.328125 0.253906         4096         4096.0        2        2      952\n",
      "0.279419 0.230713         8192         8192.0        5        2       67\n",
      "0.232727 0.186035        16384        16384.0        3        3     1738\n",
      "0.191132 0.149536        32768        32768.0        3        3       79\n",
      "0.159424 0.127716        65536        65536.0        4        4      547\n",
      "0.135880 0.112335       131072       131072.0        2        2      280\n",
      "0.117374 0.098869       262144       262144.0        5        5      691\n",
      "0.102125 0.086876       524288       524288.0        6        6      421\n",
      "0.090308 0.078491      1048576      1048576.0        1        1     1261\n",
      "0.081231 0.081231      2097152      2097152.0        5        5     2083 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1316717\n",
      "passes used = 3\n",
      "weighted example sum = 3950151.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.073110 h\n",
      "total feature number = 2345071710\n",
      "Generating 1-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_5_ngram_1_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = cache.vw\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      161\n",
      "0.500000 1.000000            2            2.0        4        1       68\n",
      "0.750000 1.000000            4            4.0        7        1       88\n",
      "0.750000 0.750000            8            8.0        7        1       95\n",
      "0.750000 0.750000           16           16.0        2        7      159\n",
      "0.750000 0.750000           32           32.0        1        7      404\n",
      "0.703125 0.656250           64           64.0        7        7      103\n",
      "0.617188 0.531250          128          128.0        5        5      276\n",
      "0.593750 0.570312          256          256.0        1        1      102\n",
      "0.533203 0.472656          512          512.0        2        5       68\n",
      "0.457031 0.380859         1024         1024.0        1        1      132\n",
      "0.383301 0.309570         2048         2048.0        7        7       71\n",
      "0.310059 0.236816         4096         4096.0        2        2      319\n",
      "0.262085 0.214111         8192         8192.0        5        5       24\n",
      "0.223450 0.184814        16384        16384.0        3        3      581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.185547 0.147644        32768        32768.0        3        3       28\n",
      "0.158493 0.131439        65536        65536.0        4        4      184\n",
      "0.137115 0.115738       131072       131072.0        2        2       95\n",
      "0.121109 0.105103       262144       262144.0        5        5      232\n",
      "0.108404 0.095699       524288       524288.0        6        6      142\n",
      "0.100007 0.091610      1048576      1048576.0        1        1      422\n",
      "0.092582 0.092582      2097152      2097152.0        5        5      696 h\n",
      "0.088155 0.083728      4194304      4194304.0        1        1      216 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1316717\n",
      "passes used = 5\n",
      "weighted example sum = 6583585.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.083287 h\n",
      "total feature number = 1313790250\n",
      "Generating 2-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_5_ngram_2_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = cache.vw\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      320\n",
      "0.500000 1.000000            2            2.0        4        1      134\n",
      "0.750000 1.000000            4            4.0        7        1      174\n",
      "0.750000 0.750000            8            8.0        7        1      188\n",
      "0.750000 0.750000           16           16.0        2        7      316\n",
      "0.718750 0.687500           32           32.0        1        7      806\n",
      "0.703125 0.687500           64           64.0        7        7      204\n",
      "0.632812 0.562500          128          128.0        5        5      550\n",
      "0.609375 0.585938          256          256.0        1        1      202\n",
      "0.531250 0.453125          512          512.0        2        5      134\n",
      "0.458984 0.386719         1024         1024.0        1        1      262\n",
      "0.382812 0.306641         2048         2048.0        7        7      140\n",
      "0.305664 0.228516         4096         4096.0        2        2      636\n",
      "0.255249 0.204834         8192         8192.0        5        7       46\n",
      "0.215027 0.174805        16384        16384.0        3        3     1160\n",
      "0.177612 0.140198        32768        32768.0        3        3       54\n",
      "0.148590 0.119568        65536        65536.0        4        4      366\n",
      "0.127281 0.105972       131072       131072.0        2        2      188\n",
      "0.110416 0.093552       262144       262144.0        5        5      462\n",
      "0.096605 0.082794       524288       524288.0        6        6      282\n",
      "0.086320 0.076035      1048576      1048576.0        1        1      842\n",
      "0.077806 0.077806      2097152      2097152.0        5        5     1390 h\n",
      "0.073817 0.069828      4194304      4194304.0        1        1      430 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1316717\n",
      "passes used = 5\n",
      "weighted example sum = 6583585.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.069835 h\n",
      "total feature number = 2614413330\n",
      "Generating 3-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_5_ngram_3_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = cache.vw\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      478\n",
      "0.500000 1.000000            2            2.0        4        1      199\n",
      "0.750000 1.000000            4            4.0        7        1      259\n",
      "0.750000 0.750000            8            8.0        7        1      280\n",
      "0.750000 0.750000           16           16.0        2        7      472\n",
      "0.718750 0.687500           32           32.0        1        7     1207\n",
      "0.687500 0.656250           64           64.0        7        7      304\n",
      "0.640625 0.593750          128          128.0        5        1      823\n",
      "0.625000 0.609375          256          256.0        1        1      301\n",
      "0.544922 0.464844          512          512.0        2        1      199\n",
      "0.466797 0.388672         1024         1024.0        1        1      391\n",
      "0.402344 0.337891         2048         2048.0        7        7      208\n",
      "0.328125 0.253906         4096         4096.0        2        2      952\n",
      "0.279419 0.230713         8192         8192.0        5        2       67\n",
      "0.232727 0.186035        16384        16384.0        3        3     1738\n",
      "0.191132 0.149536        32768        32768.0        3        3       79\n",
      "0.159424 0.127716        65536        65536.0        4        4      547\n",
      "0.135880 0.112335       131072       131072.0        2        2      280\n",
      "0.117374 0.098869       262144       262144.0        5        5      691\n",
      "0.102125 0.086876       524288       524288.0        6        6      421\n",
      "0.090308 0.078491      1048576      1048576.0        1        1     1261\n"
     ]
    }
   ],
   "source": [
    "!vw --oaa 10 -d hw8_data/stackoverflow_train.vw -f hw8_data/models/passes_3_ngram_1_model.vw  \\\n",
    "    --loss_function hinge --bit_precision 28 --random_seed 17 --cache_file cache.vw \\\n",
    "    --passes 3 --ngram 1\n",
    "\n",
    "!vw --oaa 10 -d hw8_data/stackoverflow_train.vw -f hw8_data/models/passes_3_ngram_2_model.vw  \\\n",
    "    --loss_function hinge --bit_precision 28 --random_seed 17 --cache_file cache.vw \\\n",
    "    --passes 3 --ngram 2\n",
    "\n",
    "!vw --oaa 10 -d hw8_data/stackoverflow_train.vw -f hw8_data/models/passes_3_ngram_3_model.vw  \\\n",
    "    --loss_function hinge --bit_precision 28 --random_seed 17 --cache_file cache.vw \\\n",
    "    --passes 3 --ngram 3\n",
    "\n",
    "!vw --oaa 10 -d hw8_data/stackoverflow_train.vw -f hw8_data/models/passes_5_ngram_1_model.vw  \\\n",
    "    --loss_function hinge --bit_precision 28 --random_seed 17 --cache_file cache.vw \\\n",
    "    --passes 5 --ngram 1\n",
    "\n",
    "!vw --oaa 10 -d hw8_data/stackoverflow_train.vw -f hw8_data/models/passes_5_ngram_2_model.vw  \\\n",
    "    --loss_function hinge --bit_precision 28 --random_seed 17 --cache_file cache.vw \\\n",
    "    --passes 5 --ngram 2\n",
    "\n",
    "!vw --oaa 10 -d hw8_data/stackoverflow_train.vw -f hw8_data/models/passes_5_ngram_3_model.vw  \\\n",
    "    --loss_function hinge --bit_precision 28 --random_seed 17 --cache_file cache.vw \\\n",
    "    --passes 5 --ngram 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применяем модели на valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1-grams for all namespaces.\n",
      "only testing\n",
      "predictions = hw8_data/models/passes_1_ngram_1_valid_answers.tsv\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = hw8_data/stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        9        9      186\n",
      "0.500000 1.000000            2            2.0        1        5       32\n",
      "0.250000 0.000000            4            4.0        5        5       80\n",
      "0.125000 0.000000            8            8.0        2        2       59\n",
      "0.062500 0.000000           16           16.0        6        6       38\n",
      "0.062500 0.062500           32           32.0        1        1      163\n",
      "0.078125 0.093750           64           64.0        4        4       27\n",
      "0.085938 0.093750          128          128.0        7        7      126\n",
      "0.082031 0.078125          256          256.0        7        1       97\n",
      "0.074219 0.066406          512          512.0        1        1       36\n",
      "0.072266 0.070312         1024         1024.0        2        2       89\n",
      "0.077148 0.082031         2048         2048.0        2        2       36\n",
      "0.076904 0.076660         4096         4096.0        3        3      393\n",
      "0.079712 0.082520         8192         8192.0        4        4      157\n",
      "0.081543 0.083374        16384        16384.0        4        4      149\n",
      "0.083130 0.084717        32768        32768.0        1        1      246\n",
      "0.083313 0.083496        65536        65536.0        6        6      245\n",
      "0.083023 0.082733       131072       131072.0       10       10      271\n",
      "0.082932 0.082840       262144       262144.0        3        3      659\n",
      "0.083136 0.083340       524288       524288.0        7        7      259\n",
      "0.083176 0.083216      1048576      1048576.0        7        6      576\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.083247\n",
      "total feature number = 292619835\n",
      "Generating 2-grams for all namespaces.\n",
      "only testing\n",
      "predictions = hw8_data/models/passes_1_ngram_2_valid_answers.tsv\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = hw8_data/stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        9        9      370\n",
      "0.000000 0.000000            2            2.0        1        1       62\n",
      "0.250000 0.500000            4            4.0        5        5      158\n",
      "0.250000 0.250000            8            8.0        2        2      116\n",
      "0.125000 0.000000           16           16.0        6        6       74\n",
      "0.093750 0.062500           32           32.0        1        1      324\n",
      "0.078125 0.062500           64           64.0        4        4       52\n",
      "0.078125 0.078125          128          128.0        7        7      250\n",
      "0.070312 0.062500          256          256.0        7        1      192\n",
      "0.070312 0.070312          512          512.0        1        1       70\n",
      "0.058594 0.046875         1024         1024.0        2        2      176\n",
      "0.065918 0.073242         2048         2048.0        2        2       70\n",
      "0.069336 0.072754         4096         4096.0        3        3      784\n",
      "0.067261 0.065186         8192         8192.0        4        4      312\n",
      "0.066956 0.066650        16384        16384.0        4        4      296\n",
      "0.067780 0.068604        32768        32768.0        1        1      490\n",
      "0.068161 0.068542        65536        65536.0        6        6      488\n",
      "0.067421 0.066681       131072       131072.0       10       10      540\n",
      "0.067314 0.067207       262144       262144.0        3        3     1316\n",
      "0.067661 0.068008       524288       524288.0        7        7      516\n",
      "0.067592 0.067522      1048576      1048576.0        7        6     1150\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.067465\n",
      "total feature number = 582313634\n",
      "Generating 3-grams for all namespaces.\n",
      "only testing\n",
      "predictions = hw8_data/models/passes_1_ngram_3_valid_answers.tsv\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = hw8_data/stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        9        9      553\n",
      "0.000000 0.000000            2            2.0        1        1       91\n",
      "0.000000 0.000000            4            4.0        5        5      235\n",
      "0.125000 0.250000            8            8.0        2        2      172\n",
      "0.062500 0.000000           16           16.0        6        6      109\n",
      "0.062500 0.062500           32           32.0        1        1      484\n",
      "0.062500 0.062500           64           64.0        4        4       76\n",
      "0.085938 0.109375          128          128.0        7        7      373\n",
      "0.093750 0.101562          256          256.0        7        1      286\n",
      "0.082031 0.070312          512          512.0        1        1      103\n",
      "0.073242 0.064453         1024         1024.0        2        2      262\n",
      "0.077148 0.081055         2048         2048.0        2        2      103\n",
      "0.075195 0.073242         4096         4096.0        3        3     1174\n",
      "0.072388 0.069580         8192         8192.0        4        4      466\n",
      "0.071472 0.070557        16384        16384.0        4        4      442\n",
      "0.071625 0.071777        32768        32768.0        1        1      733\n",
      "0.071747 0.071869        65536        65536.0        6        6      730\n",
      "0.070839 0.069931       131072       131072.0       10       10      808\n",
      "0.070099 0.069359       262144       262144.0        3        3     1972\n",
      "0.070360 0.070621       524288       524288.0        7        7      772\n",
      "0.070249 0.070137      1048576      1048576.0        7        6     1723\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.070123\n",
      "total feature number = 870544416\n",
      "Generating 1-grams for all namespaces.\n",
      "only testing\n",
      "predictions = hw8_data/models/passes_3_ngram_1_valid_answers.tsv\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = hw8_data/stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        9        9      186\n",
      "0.500000 1.000000            2            2.0        1        5       32\n",
      "0.250000 0.000000            4            4.0        5        5       80\n",
      "0.125000 0.000000            8            8.0        2        2       59\n",
      "0.062500 0.000000           16           16.0        6        6       38\n",
      "0.062500 0.062500           32           32.0        1        1      163\n",
      "0.078125 0.093750           64           64.0        4        4       27\n",
      "0.085938 0.093750          128          128.0        7        7      126\n",
      "0.082031 0.078125          256          256.0        7        1       97\n",
      "0.074219 0.066406          512          512.0        1        1       36\n",
      "0.069336 0.064453         1024         1024.0        2        2       89\n",
      "0.078613 0.087891         2048         2048.0        2        2       36\n",
      "0.077148 0.075684         4096         4096.0        3        3      393\n",
      "0.079224 0.081299         8192         8192.0        4        4      157\n",
      "0.080139 0.081055        16384        16384.0        4        4      149\n",
      "0.081635 0.083130        32768        32768.0        1        1      246\n",
      "0.081863 0.082092        65536        65536.0        6        6      245\n",
      "0.081352 0.080841       131072       131072.0       10       10      271\n",
      "0.081676 0.082001       262144       262144.0        3        3      659\n",
      "0.081945 0.082214       524288       524288.0        7        7      259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.081898 0.081850      1048576      1048576.0        7        6      576\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.081903\n",
      "total feature number = 292619835\n",
      "Generating 2-grams for all namespaces.\n",
      "only testing\n",
      "predictions = hw8_data/models/passes_3_ngram_2_valid_answers.tsv\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = hw8_data/stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        9        9      370\n",
      "0.000000 0.000000            2            2.0        1        1       62\n",
      "0.000000 0.000000            4            4.0        5        5      158\n",
      "0.000000 0.000000            8            8.0        2        2      116\n",
      "0.000000 0.000000           16           16.0        6        6       74\n",
      "0.031250 0.062500           32           32.0        1        1      324\n",
      "0.046875 0.062500           64           64.0        4        4       52\n",
      "0.054688 0.062500          128          128.0        7        7      250\n",
      "0.066406 0.078125          256          256.0        7        1      192\n",
      "0.066406 0.066406          512          512.0        1        1       70\n",
      "0.064453 0.062500         1024         1024.0        2        2      176\n",
      "0.069336 0.074219         2048         2048.0        2        2       70\n",
      "0.068848 0.068359         4096         4096.0        3        3      784\n",
      "0.068970 0.069092         8192         8192.0        4        4      312\n",
      "0.067932 0.066895        16384        16384.0        4        4      296\n",
      "0.069641 0.071350        32768        32768.0        1        1      490\n",
      "0.070160 0.070679        65536        65536.0        6        6      488\n",
      "0.069542 0.068924       131072       131072.0       10       10      540\n",
      "0.069530 0.069519       262144       262144.0        3        3     1316\n",
      "0.069754 0.069977       524288       524288.0        7        7      516\n",
      "0.069634 0.069515      1048576      1048576.0        7        6     1150\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.069456\n",
      "total feature number = 582313634\n",
      "Generating 3-grams for all namespaces.\n",
      "only testing\n",
      "predictions = hw8_data/models/passes_3_ngram_3_valid_answers.tsv\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = hw8_data/stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        9        9      553\n",
      "0.000000 0.000000            2            2.0        1        1       91\n",
      "0.000000 0.000000            4            4.0        5        5      235\n",
      "0.000000 0.000000            8            8.0        2        2      172\n",
      "0.000000 0.000000           16           16.0        6        6      109\n",
      "0.031250 0.062500           32           32.0        1        1      484\n",
      "0.046875 0.062500           64           64.0        4        4       76\n",
      "0.062500 0.078125          128          128.0        7        7      373\n",
      "0.078125 0.093750          256          256.0        7        1      286\n",
      "0.076172 0.074219          512          512.0        1        1      103\n",
      "0.072266 0.068359         1024         1024.0        2        2      262\n",
      "0.076660 0.081055         2048         2048.0        2        2      103\n",
      "0.074463 0.072266         4096         4096.0        3        3     1174\n",
      "0.073364 0.072266         8192         8192.0        4        4      466\n",
      "0.073303 0.073242        16384        16384.0        4        4      442\n",
      "0.074005 0.074707        32768        32768.0        1        1      733\n",
      "0.074203 0.074402        65536        65536.0        6        6      730\n",
      "0.073288 0.072372       131072       131072.0       10       10      808\n",
      "0.073036 0.072784       262144       262144.0        3        3     1972\n",
      "0.073133 0.073231       524288       524288.0        7        7      772\n",
      "0.073140 0.073147      1048576      1048576.0        7        6     1723\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.072842\n",
      "total feature number = 870544416\n",
      "Generating 1-grams for all namespaces.\n",
      "only testing\n",
      "predictions = hw8_data/models/passes_5_ngram_1_valid_answers.tsv\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = hw8_data/stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        9        9      186\n",
      "0.500000 1.000000            2            2.0        1        5       32\n",
      "0.250000 0.000000            4            4.0        5        5       80\n",
      "0.125000 0.000000            8            8.0        2        2       59\n",
      "0.062500 0.000000           16           16.0        6        6       38\n",
      "0.062500 0.062500           32           32.0        1        1      163\n",
      "0.078125 0.093750           64           64.0        4        4       27\n",
      "0.085938 0.093750          128          128.0        7        7      126\n",
      "0.078125 0.070312          256          256.0        7        1       97\n",
      "0.072266 0.066406          512          512.0        1        1       36\n",
      "0.072266 0.072266         1024         1024.0        2        2       89\n",
      "0.079102 0.085938         2048         2048.0        2        2       36\n",
      "0.078857 0.078613         4096         4096.0        3        3      393\n",
      "0.079834 0.080811         8192         8192.0        4        4      157\n",
      "0.080811 0.081787        16384        16384.0        4        4      149\n",
      "0.082428 0.084045        32768        32768.0        1        1      246\n",
      "0.082016 0.081604        65536        65536.0        6        6      245\n",
      "0.081940 0.081863       131072       131072.0       10       10      271\n",
      "0.082077 0.082214       262144       262144.0        3        3      659\n",
      "0.082058 0.082039       524288       524288.0        7        7      259\n",
      "0.081935 0.081812      1048576      1048576.0        7        6      576\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.081966\n",
      "total feature number = 292619835\n",
      "Generating 2-grams for all namespaces.\n",
      "only testing\n",
      "predictions = hw8_data/models/passes_5_ngram_2_valid_answers.tsv\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = hw8_data/stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        9        9      370\n",
      "0.000000 0.000000            2            2.0        1        1       62\n",
      "0.000000 0.000000            4            4.0        5        5      158\n",
      "0.125000 0.250000            8            8.0        2        2      116\n",
      "0.062500 0.000000           16           16.0        6        6       74\n",
      "0.062500 0.062500           32           32.0        1        1      324\n",
      "0.062500 0.062500           64           64.0        4        4       52\n",
      "0.070312 0.078125          128          128.0        7        7      250\n",
      "0.070312 0.070312          256          256.0        7        1      192\n",
      "0.070312 0.070312          512          512.0        1        1       70\n",
      "0.062500 0.054688         1024         1024.0        2        2      176\n",
      "0.067871 0.073242         2048         2048.0        2        2       70\n",
      "0.068604 0.069336         4096         4096.0        3        3      784\n",
      "0.067871 0.067139         8192         8192.0        4        4      312\n",
      "0.068054 0.068237        16384        16384.0        4        4      296\n",
      "0.068848 0.069641        32768        32768.0        1        1      490\n",
      "0.069504 0.070160        65536        65536.0        6        6      488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.068810 0.068115       131072       131072.0       10       10      540\n",
      "0.069115 0.069420       262144       262144.0        3        3     1316\n",
      "0.069130 0.069145       524288       524288.0        7        7      516\n",
      "0.069003 0.068876      1048576      1048576.0        7        6     1150\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.068798\n",
      "total feature number = 582313634\n",
      "Generating 3-grams for all namespaces.\n",
      "only testing\n",
      "predictions = hw8_data/models/passes_5_ngram_3_valid_answers.tsv\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = hw8_data/stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        9        9      553\n",
      "0.000000 0.000000            2            2.0        1        1       91\n",
      "0.000000 0.000000            4            4.0        5        5      235\n",
      "0.125000 0.250000            8            8.0        2        2      172\n",
      "0.062500 0.000000           16           16.0        6        6      109\n",
      "0.062500 0.062500           32           32.0        1        1      484\n",
      "0.062500 0.062500           64           64.0        4        4       76\n",
      "0.062500 0.062500          128          128.0        7        7      373\n",
      "0.078125 0.093750          256          256.0        7        1      286\n",
      "0.076172 0.074219          512          512.0        1        1      103\n",
      "0.074219 0.072266         1024         1024.0        2        2      262\n",
      "0.076660 0.079102         2048         2048.0        2        2      103\n",
      "0.073486 0.070312         4096         4096.0        3        3     1174\n",
      "0.072754 0.072021         8192         8192.0        4        4      466\n",
      "0.072510 0.072266        16384        16384.0        4        4      442\n",
      "0.073395 0.074280        32768        32768.0        1        1      733\n",
      "0.073639 0.073883        65536        65536.0        6        6      730\n",
      "0.072670 0.071701       131072       131072.0       10       10      808\n",
      "0.072289 0.071907       262144       262144.0        3        3     1972\n",
      "0.072346 0.072403       524288       524288.0        7        7      772\n",
      "0.072211 0.072077      1048576      1048576.0        7        6     1723\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.071918\n",
      "total feature number = 870544416\n"
     ]
    }
   ],
   "source": [
    "!vw -i hw8_data/models/passes_1_ngram_1_model.vw -t -d hw8_data/stackoverflow_valid.vw \\\n",
    "    -p hw8_data/models/passes_1_ngram_1_valid_answers.tsv\n",
    "\n",
    "!vw -i hw8_data/models/passes_1_ngram_2_model.vw -t -d hw8_data/stackoverflow_valid.vw \\\n",
    "    -p hw8_data/models/passes_1_ngram_2_valid_answers.tsv\n",
    "\n",
    "!vw -i hw8_data/models/passes_1_ngram_3_model.vw -t -d hw8_data/stackoverflow_valid.vw \\\n",
    "    -p hw8_data/models/passes_1_ngram_3_valid_answers.tsv\n",
    "\n",
    "!vw -i hw8_data/models/passes_3_ngram_1_model.vw -t -d hw8_data/stackoverflow_valid.vw \\\n",
    "    -p hw8_data/models/passes_3_ngram_1_valid_answers.tsv\n",
    "\n",
    "!vw -i hw8_data/models/passes_3_ngram_2_model.vw -t -d hw8_data/stackoverflow_valid.vw \\\n",
    "    -p hw8_data/models/passes_3_ngram_2_valid_answers.tsv\n",
    "\n",
    "!vw -i hw8_data/models/passes_3_ngram_3_model.vw -t -d hw8_data/stackoverflow_valid.vw \\\n",
    "    -p hw8_data/models/passes_3_ngram_3_valid_answers.tsv\n",
    "\n",
    "!vw -i hw8_data/models/passes_5_ngram_1_model.vw -t -d hw8_data/stackoverflow_valid.vw \\\n",
    "    -p hw8_data/models/passes_5_ngram_1_valid_answers.tsv\n",
    "\n",
    "!vw -i hw8_data/models/passes_5_ngram_2_model.vw -t -d hw8_data/stackoverflow_valid.vw \\\n",
    "    -p hw8_data/models/passes_5_ngram_2_valid_answers.tsv\n",
    "\n",
    "!vw -i hw8_data/models/passes_5_ngram_3_model.vw -t -d hw8_data/stackoverflow_valid.vw \\\n",
    "    -p hw8_data/models/passes_5_ngram_3_valid_answers.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# То же самое без hinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_1_ngram_1_squared_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using cache_file = cache.vw\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      161\n",
      "0.500000 1.000000            2            2.0        4        1       68\n",
      "0.750000 1.000000            4            4.0        7        1       88\n",
      "0.750000 0.750000            8            8.0        7        1       95\n",
      "0.812500 0.875000           16           16.0        7        7      209\n",
      "0.812500 0.812500           32           32.0        7        5      174\n",
      "0.781250 0.750000           64           64.0        3        3      204\n",
      "0.671875 0.562500          128          128.0        1        5       29\n",
      "0.609375 0.546875          256          256.0        5        5      169\n",
      "0.541016 0.472656          512          512.0        2        2      303\n",
      "0.451172 0.361328         1024         1024.0        3        3      123\n",
      "0.375977 0.300781         2048         2048.0        1        5       83\n",
      "0.311523 0.247070         4096         4096.0        1        1       79\n",
      "0.269287 0.227051         8192         8192.0        2        2      112\n",
      "0.226868 0.184448        16384        16384.0        7        7      252\n",
      "0.188995 0.151123        32768        32768.0        4        5      134\n",
      "0.162979 0.136963        65536        65536.0        5        5      145\n",
      "0.141563 0.120148       131072       131072.0        7        2      255\n",
      "0.123829 0.106094       262144       262144.0        7        7      101\n",
      "0.112276 0.100723       524288       524288.0        1        1      818\n",
      "0.103135 0.093994      1048576      1048576.0        1        1      571\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.098891\n",
      "total feature number = 291954690\n",
      "Generating 2-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_1_ngram_2_squared_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using cache_file = cache.vw\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      320\n",
      "0.500000 1.000000            2            2.0        4        1      134\n",
      "0.750000 1.000000            4            4.0        7        1      174\n",
      "0.750000 0.750000            8            8.0        7        1      188\n",
      "0.750000 0.750000           16           16.0        7        7      416\n",
      "0.781250 0.812500           32           32.0        7        2      346\n",
      "0.765625 0.750000           64           64.0        3        3      406\n",
      "0.664062 0.562500          128          128.0        1        7       56\n",
      "0.597656 0.531250          256          256.0        5        3      336\n",
      "0.527344 0.457031          512          512.0        2        2      604\n",
      "0.429688 0.332031         1024         1024.0        3        3      244\n",
      "0.362793 0.295898         2048         2048.0        1        5      164\n",
      "0.298096 0.233398         4096         4096.0        1        1      156\n",
      "0.249878 0.201660         8192         8192.0        2        2      222\n",
      "0.210266 0.170654        16384        16384.0        7        7      502\n",
      "0.175262 0.140259        32768        32768.0        4        5      266\n",
      "0.148163 0.121063        65536        65536.0        5        5      288\n",
      "0.127380 0.106598       131072       131072.0        7        2      508\n",
      "0.109459 0.091537       262144       262144.0        7        7      200\n",
      "0.097469 0.085480       524288       524288.0        1        1     1634\n",
      "0.087222 0.076975      1048576      1048576.0        1        1     1140\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.083143\n",
      "total feature number = 580983344\n",
      "Generating 3-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_1_ngram_3_squared_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using cache_file = cache.vw\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      478\n",
      "0.500000 1.000000            2            2.0        4        1      199\n",
      "0.750000 1.000000            4            4.0        7        1      259\n",
      "0.750000 0.750000            8            8.0        7        1      280\n",
      "0.750000 0.750000           16           16.0        7        7      622\n",
      "0.781250 0.812500           32           32.0        7        2      517\n",
      "0.765625 0.750000           64           64.0        3        3      607\n",
      "0.656250 0.546875          128          128.0        1        7       82\n",
      "0.605469 0.554688          256          256.0        5        1      502\n",
      "0.535156 0.464844          512          512.0        2        2      904\n",
      "0.442383 0.349609         1024         1024.0        3        3      364\n",
      "0.380371 0.318359         2048         2048.0        1        5      244\n",
      "0.317383 0.254395         4096         4096.0        1        1      232\n",
      "0.266724 0.216064         8192         8192.0        2        2      331\n",
      "0.222290 0.177856        16384        16384.0        7        7      751\n",
      "0.184631 0.146973        32768        32768.0        4        5      397\n",
      "0.155502 0.126373        65536        65536.0        5        5      430\n",
      "0.132919 0.110336       131072       131072.0        7        7      760\n",
      "0.113468 0.094017       262144       262144.0        7        7      298\n",
      "0.101650 0.089832       524288       524288.0        1        1     2449\n",
      "0.090106 0.078562      1048576      1048576.0        1        1     1708\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.086319\n",
      "total feature number = 868548985\n",
      "Generating 1-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_3_ngram_1_squared_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = cache.vw\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      161\n",
      "0.500000 1.000000            2            2.0        4        1       68\n",
      "0.750000 1.000000            4            4.0        7        1       88\n",
      "0.750000 0.750000            8            8.0        7        1       95\n",
      "0.750000 0.750000           16           16.0        2        7      159\n",
      "0.781250 0.812500           32           32.0        1        7      404\n",
      "0.718750 0.656250           64           64.0        7        7      103\n",
      "0.664062 0.609375          128          128.0        5        5      276\n",
      "0.625000 0.585938          256          256.0        1        1      102\n",
      "0.546875 0.468750          512          512.0        2        5       68\n",
      "0.450195 0.353516         1024         1024.0        1        1      132\n",
      "0.387207 0.324219         2048         2048.0        7        7       71\n",
      "0.318115 0.249023         4096         4096.0        2        2      319\n",
      "0.267578 0.217041         8192         8192.0        5        2       24\n",
      "0.227661 0.187744        16384        16384.0        3        3      581\n",
      "0.190674 0.153687        32768        32768.0        3        3       28\n",
      "0.164215 0.137756        65536        65536.0        4        4      184\n",
      "0.142067 0.119919       131072       131072.0        2        2       95\n",
      "0.125511 0.108955       262144       262144.0        5        5      232\n",
      "0.112453 0.099396       524288       524288.0        6        6      142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.103467 0.094481      1048576      1048576.0        1        1      422\n",
      "0.096123 0.096123      2097152      2097152.0        5        5      696 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1316717\n",
      "passes used = 3\n",
      "weighted example sum = 3950151.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.088127 h\n",
      "total feature number = 788274150\n",
      "Generating 2-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_3_ngram_2_squared_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = cache.vw\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      320\n",
      "0.500000 1.000000            2            2.0        4        1      134\n",
      "0.750000 1.000000            4            4.0        7        1      174\n",
      "0.750000 0.750000            8            8.0        7        1      188\n",
      "0.687500 0.625000           16           16.0        2        7      316\n",
      "0.687500 0.687500           32           32.0        1        7      806\n",
      "0.687500 0.687500           64           64.0        7        7      204\n",
      "0.601562 0.515625          128          128.0        5        5      550\n",
      "0.574219 0.546875          256          256.0        1        1      202\n",
      "0.503906 0.433594          512          512.0        2        5      134\n",
      "0.432617 0.361328         1024         1024.0        1        1      262\n",
      "0.370605 0.308594         2048         2048.0        7        7      140\n",
      "0.299072 0.227539         4096         4096.0        2        2      636\n",
      "0.252197 0.205322         8192         8192.0        5        2       46\n",
      "0.215515 0.178833        16384        16384.0        3        3     1160\n",
      "0.178619 0.141724        32768        32768.0        3        3       54\n",
      "0.149918 0.121216        65536        65536.0        4        4      366\n",
      "0.128204 0.106491       131072       131072.0        2        2      188\n",
      "0.111256 0.094307       262144       262144.0        5        5      462\n",
      "0.097771 0.084286       524288       524288.0        6        6      282\n",
      "0.087828 0.077885      1048576      1048576.0        1        1      842\n",
      "0.079544 0.079544      2097152      2097152.0        5        5     1390 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1316717\n",
      "passes used = 3\n",
      "weighted example sum = 3950151.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.071948 h\n",
      "total feature number = 1568647998\n",
      "Generating 3-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_3_ngram_3_squared_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = cache.vw\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      478\n",
      "0.500000 1.000000            2            2.0        4        1      199\n",
      "0.750000 1.000000            4            4.0        7        1      259\n",
      "0.750000 0.750000            8            8.0        7        1      280\n",
      "0.750000 0.750000           16           16.0        2        7      472\n",
      "0.750000 0.750000           32           32.0        1        7     1207\n",
      "0.718750 0.687500           64           64.0        7        7      304\n",
      "0.640625 0.562500          128          128.0        5        5      823\n",
      "0.609375 0.578125          256          256.0        1        1      301\n",
      "0.521484 0.433594          512          512.0        2        5      199\n",
      "0.442383 0.363281         1024         1024.0        1        1      391\n",
      "0.378906 0.315430         2048         2048.0        7        7      208\n",
      "0.310791 0.242676         4096         4096.0        2        2      952\n",
      "0.265747 0.220703         8192         8192.0        5        2       67\n",
      "0.223755 0.181763        16384        16384.0        3        3     1738\n",
      "0.186035 0.148315        32768        32768.0        3        3       79\n",
      "0.155670 0.125305        65536        65536.0        4        4      547\n",
      "0.133133 0.110596       131072       131072.0        2        2      280\n",
      "0.115284 0.097435       262144       262144.0        5        5      691\n",
      "0.101097 0.086910       524288       524288.0        6        6      421\n",
      "0.090279 0.079460      1048576      1048576.0        1        1     1261\n",
      "0.081248 0.081248      2097152      2097152.0        5        5     2083 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1316717\n",
      "passes used = 3\n",
      "weighted example sum = 3950151.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.074053 h\n",
      "total feature number = 2345071710\n",
      "Generating 1-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_5_ngram_1_squared_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = cache.vw\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      161\n",
      "0.500000 1.000000            2            2.0        4        1       68\n",
      "0.750000 1.000000            4            4.0        7        1       88\n",
      "0.750000 0.750000            8            8.0        7        1       95\n",
      "0.750000 0.750000           16           16.0        2        7      159\n",
      "0.781250 0.812500           32           32.0        1        7      404\n",
      "0.718750 0.656250           64           64.0        7        7      103\n",
      "0.664062 0.609375          128          128.0        5        5      276\n",
      "0.625000 0.585938          256          256.0        1        1      102\n",
      "0.546875 0.468750          512          512.0        2        5       68\n",
      "0.450195 0.353516         1024         1024.0        1        1      132\n",
      "0.387207 0.324219         2048         2048.0        7        7       71\n",
      "0.318115 0.249023         4096         4096.0        2        2      319\n",
      "0.267578 0.217041         8192         8192.0        5        2       24\n",
      "0.227661 0.187744        16384        16384.0        3        3      581\n",
      "0.190674 0.153687        32768        32768.0        3        3       28\n",
      "0.164215 0.137756        65536        65536.0        4        4      184\n",
      "0.142067 0.119919       131072       131072.0        2        2       95\n",
      "0.125511 0.108955       262144       262144.0        5        5      232\n",
      "0.112453 0.099396       524288       524288.0        6        6      142\n",
      "0.103467 0.094481      1048576      1048576.0        1        1      422\n",
      "0.096123 0.096123      2097152      2097152.0        5        5      696 h\n",
      "0.092116 0.088110      4194304      4194304.0        1        1      216 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1316717\n",
      "passes used = 5\n",
      "weighted example sum = 6583585.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.087887 h\n",
      "total feature number = 1313790250\n",
      "Generating 2-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_5_ngram_2_squared_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = cache.vw\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      320\n",
      "0.500000 1.000000            2            2.0        4        1      134\n",
      "0.750000 1.000000            4            4.0        7        1      174\n",
      "0.750000 0.750000            8            8.0        7        1      188\n",
      "0.687500 0.625000           16           16.0        2        7      316\n",
      "0.687500 0.687500           32           32.0        1        7      806\n",
      "0.687500 0.687500           64           64.0        7        7      204\n",
      "0.601562 0.515625          128          128.0        5        5      550\n",
      "0.574219 0.546875          256          256.0        1        1      202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.503906 0.433594          512          512.0        2        5      134\n",
      "0.432617 0.361328         1024         1024.0        1        1      262\n",
      "0.370605 0.308594         2048         2048.0        7        7      140\n",
      "0.299072 0.227539         4096         4096.0        2        2      636\n",
      "0.252197 0.205322         8192         8192.0        5        2       46\n",
      "0.215515 0.178833        16384        16384.0        3        3     1160\n",
      "0.178619 0.141724        32768        32768.0        3        3       54\n",
      "0.149918 0.121216        65536        65536.0        4        4      366\n",
      "0.128204 0.106491       131072       131072.0        2        2      188\n",
      "0.111256 0.094307       262144       262144.0        5        5      462\n",
      "0.097771 0.084286       524288       524288.0        6        6      282\n",
      "0.087828 0.077885      1048576      1048576.0        1        1      842\n",
      "0.079544 0.079544      2097152      2097152.0        5        5     1390 h\n",
      "0.075870 0.072197      4194304      4194304.0        1        1      430 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1316717\n",
      "passes used = 5\n",
      "weighted example sum = 6583585.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.071948 h\n",
      "total feature number = 2614413330\n",
      "Generating 3-grams for all namespaces.\n",
      "final_regressor = hw8_data/models/passes_5_ngram_3_squared_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = cache.vw\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      478\n",
      "0.500000 1.000000            2            2.0        4        1      199\n",
      "0.750000 1.000000            4            4.0        7        1      259\n",
      "0.750000 0.750000            8            8.0        7        1      280\n",
      "0.750000 0.750000           16           16.0        2        7      472\n",
      "0.750000 0.750000           32           32.0        1        7     1207\n",
      "0.718750 0.687500           64           64.0        7        7      304\n",
      "0.640625 0.562500          128          128.0        5        5      823\n",
      "0.609375 0.578125          256          256.0        1        1      301\n",
      "0.521484 0.433594          512          512.0        2        5      199\n",
      "0.442383 0.363281         1024         1024.0        1        1      391\n",
      "0.378906 0.315430         2048         2048.0        7        7      208\n",
      "0.310791 0.242676         4096         4096.0        2        2      952\n",
      "0.265747 0.220703         8192         8192.0        5        2       67\n",
      "0.223755 0.181763        16384        16384.0        3        3     1738\n",
      "0.186035 0.148315        32768        32768.0        3        3       79\n",
      "0.155670 0.125305        65536        65536.0        4        4      547\n",
      "0.133133 0.110596       131072       131072.0        2        2      280\n",
      "0.115284 0.097435       262144       262144.0        5        5      691\n",
      "0.101097 0.086910       524288       524288.0        6        6      421\n",
      "0.090279 0.079460      1048576      1048576.0        1        1     1261\n",
      "0.081248 0.081248      2097152      2097152.0        5        5     2083 h\n",
      "0.077922 0.074596      4194304      4194304.0        1        1      643 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1316717\n",
      "passes used = 5\n",
      "weighted example sum = 6583585.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.074053 h\n",
      "total feature number = 3908452850\n",
      "Generating 1-grams for all namespaces.\n",
      "only testing\n",
      "predictions = hw8_data/models/passes_1_ngram_1_squared_valid_answers.tsv\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = hw8_data/stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        9        9      186\n",
      "0.000000 0.000000            2            2.0        1        1       32\n",
      "0.000000 0.000000            4            4.0        5        5       80\n",
      "0.000000 0.000000            8            8.0        2        2       59\n",
      "0.000000 0.000000           16           16.0        6        6       38\n",
      "0.031250 0.062500           32           32.0        1        1      163\n",
      "0.078125 0.125000           64           64.0        4        7       27\n",
      "0.085938 0.093750          128          128.0        7        7      126\n",
      "0.070312 0.054688          256          256.0        7        1       97\n",
      "0.070312 0.070312          512          512.0        1        1       36\n",
      "0.080078 0.089844         1024         1024.0        2        2       89\n",
      "0.082031 0.083984         2048         2048.0        2        2       36\n",
      "0.081299 0.080566         4096         4096.0        3        3      393\n",
      "0.083862 0.086426         8192         8192.0        4        4      157\n",
      "0.084839 0.085815        16384        16384.0        4        4      149\n",
      "0.084869 0.084900        32768        32768.0        1        1      246\n",
      "0.085510 0.086151        65536        65536.0        6        6      245\n",
      "0.085022 0.084534       131072       131072.0       10       10      271\n",
      "0.085304 0.085587       262144       262144.0        3        3      659\n",
      "0.085186 0.085068       524288       524288.0        7        7      259\n",
      "0.084997 0.084808      1048576      1048576.0        7        6      576\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.084985\n",
      "total feature number = 292619835\n",
      "Generating 2-grams for all namespaces.\n",
      "only testing\n",
      "predictions = hw8_data/models/passes_1_ngram_2_squared_valid_answers.tsv\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = hw8_data/stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        9        9      370\n",
      "0.000000 0.000000            2            2.0        1        1       62\n",
      "0.000000 0.000000            4            4.0        5        5      158\n",
      "0.000000 0.000000            8            8.0        2        2      116\n",
      "0.000000 0.000000           16           16.0        6        6       74\n",
      "0.031250 0.062500           32           32.0        1        1      324\n",
      "0.046875 0.062500           64           64.0        4        4       52\n",
      "0.054688 0.062500          128          128.0        7        7      250\n",
      "0.066406 0.078125          256          256.0        7        1      192\n",
      "0.072266 0.078125          512          512.0        1        1       70\n",
      "0.064453 0.056641         1024         1024.0        2        2      176\n",
      "0.070801 0.077148         2048         2048.0        2        2       70\n",
      "0.070801 0.070801         4096         4096.0        3        3      784\n",
      "0.071533 0.072266         8192         8192.0        4        4      312\n",
      "0.070557 0.069580        16384        16384.0        4        4      296\n",
      "0.070068 0.069580        32768        32768.0        1        1      490\n",
      "0.070465 0.070862        65536        65536.0        6        6      488\n",
      "0.069366 0.068268       131072       131072.0       10       10      540\n",
      "0.068977 0.068588       262144       262144.0        3        3     1316\n",
      "0.069117 0.069256       524288       524288.0        7        7      516\n",
      "0.069041 0.068966      1048576      1048576.0        7        6     1150\n"
     ]
    }
   ],
   "source": [
    "!vw --oaa 10 -d hw8_data/stackoverflow_train.vw -f hw8_data/models/passes_1_ngram_1_squared_model.vw  \\\n",
    "    --bit_precision 28 --random_seed 17 --cache_file cache.vw \\\n",
    "    --passes 1 --ngram 1\n",
    "\n",
    "!vw --oaa 10 -d hw8_data/stackoverflow_train.vw -f hw8_data/models/passes_1_ngram_2_squared_model.vw  \\\n",
    "    --bit_precision 28 --random_seed 17 --cache_file cache.vw \\\n",
    "    --passes 1 --ngram 2\n",
    "\n",
    "!vw --oaa 10 -d hw8_data/stackoverflow_train.vw -f hw8_data/models/passes_1_ngram_3_squared_model.vw  \\\n",
    "    --bit_precision 28 --random_seed 17 --cache_file cache.vw \\\n",
    "    --passes 1 --ngram 3\n",
    "\n",
    "!vw --oaa 10 -d hw8_data/stackoverflow_train.vw -f hw8_data/models/passes_3_ngram_1_squared_model.vw  \\\n",
    "    --bit_precision 28 --random_seed 17 --cache_file cache.vw \\\n",
    "    --passes 3 --ngram 1\n",
    "\n",
    "!vw --oaa 10 -d hw8_data/stackoverflow_train.vw -f hw8_data/models/passes_3_ngram_2_squared_model.vw  \\\n",
    "    --bit_precision 28 --random_seed 17 --cache_file cache.vw \\\n",
    "    --passes 3 --ngram 2\n",
    "\n",
    "!vw --oaa 10 -d hw8_data/stackoverflow_train.vw -f hw8_data/models/passes_3_ngram_3_squared_model.vw  \\\n",
    "    --bit_precision 28 --random_seed 17 --cache_file cache.vw \\\n",
    "    --passes 3 --ngram 3\n",
    "\n",
    "!vw --oaa 10 -d hw8_data/stackoverflow_train.vw -f hw8_data/models/passes_5_ngram_1_squared_model.vw  \\\n",
    "    --bit_precision 28 --random_seed 17 --cache_file cache.vw \\\n",
    "    --passes 5 --ngram 1\n",
    "\n",
    "!vw --oaa 10 -d hw8_data/stackoverflow_train.vw -f hw8_data/models/passes_5_ngram_2_squared_model.vw  \\\n",
    "    --bit_precision 28 --random_seed 17 --cache_file cache.vw \\\n",
    "    --passes 5 --ngram 2\n",
    "\n",
    "!vw --oaa 10 -d hw8_data/stackoverflow_train.vw -f hw8_data/models/passes_5_ngram_3_squared_model.vw  \\\n",
    "    --bit_precision 28 --random_seed 17 --cache_file cache.vw \\\n",
    "    --passes 5 --ngram 3\n",
    "\n",
    "!vw -i hw8_data/models/passes_1_ngram_1_squared_model.vw -t -d hw8_data/stackoverflow_valid.vw \\\n",
    "    -p hw8_data/models/passes_1_ngram_1_squared_valid_answers.tsv\n",
    "\n",
    "!vw -i hw8_data/models/passes_1_ngram_2_squared_model.vw -t -d hw8_data/stackoverflow_valid.vw \\\n",
    "    -p hw8_data/models/passes_1_ngram_2_squared_valid_answers.tsv\n",
    "\n",
    "!vw -i hw8_data/models/passes_1_ngram_3_squared_model.vw -t -d hw8_data/stackoverflow_valid.vw \\\n",
    "    -p hw8_data/models/passes_1_ngram_3_squared_valid_answers.tsv\n",
    "\n",
    "!vw -i hw8_data/models/passes_3_ngram_1_squared_model.vw -t -d hw8_data/stackoverflow_valid.vw \\\n",
    "    -p hw8_data/models/passes_3_ngram_1_squared_valid_answers.tsv\n",
    "\n",
    "!vw -i hw8_data/models/passes_3_ngram_2_squared_model.vw -t -d hw8_data/stackoverflow_valid.vw \\\n",
    "    -p hw8_data/models/passes_3_ngram_2_squared_valid_answers.tsv\n",
    "\n",
    "!vw -i hw8_data/models/passes_3_ngram_3_squared_model.vw -t -d hw8_data/stackoverflow_valid.vw \\\n",
    "    -p hw8_data/models/passes_3_ngram_3_squared_valid_answers.tsv\n",
    "\n",
    "!vw -i hw8_data/models/passes_5_ngram_1_squared_model.vw -t -d hw8_data/stackoverflow_valid.vw \\\n",
    "    -p hw8_data/models/passes_5_ngram_1_squared_valid_answers.tsv\n",
    "\n",
    "!vw -i hw8_data/models/passes_5_ngram_2_squared_model.vw -t -d hw8_data/stackoverflow_valid.vw \\\n",
    "    -p hw8_data/models/passes_5_ngram_2_squared_valid_answers.tsv\n",
    "\n",
    "!vw -i hw8_data/models/passes_5_ngram_3_squared_model.vw -t -d hw8_data/stackoverflow_valid.vw \\\n",
    "    -p hw8_data/models/passes_5_ngram_3_squared_valid_answers.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
